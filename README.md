# Titanic â€“ Machine Learning from Disaster

A clean, modular starter repo for the classic [Kaggle Titanic competition](https://www.kaggle.com/c/titanic).  
This repo contains reproducible pipelines, strong feature engineering, and model tuning scripts to reach competitive leaderboard scores.

---

## ğŸš€ Features

- **Modular structure**: `src/` with clear separation of features, models, tuning, and utilities.  
- **Feature engineering**:
  - `Title` extraction + rare grouping  
  - `FamilySize`, `IsAlone`, and **FamilyGroup buckets**  
  - `TicketPrefix`, **TicketGroupSize**  
  - `CabinDeck` extraction  
  - `FareLog` transformation  
  - Interaction features: `SexÃ—Pclass`, `IsAloneÃ—Sex`  
  - Quantile binning for `Age` and `Fare`  
- **Models supported**:
  - Logistic Regression (with tuning for C, solver, penalty, class weight)  
  - Random Forest (randomized hyperparameter search)  
  - HistGradientBoostingClassifier (grid search, dense preprocessing)  
  - Soft-voting ensemble of LR + RF  
- **Cross-validation**: Stratified 5-fold CV for reliable estimates.  
- **Automated submission**: Best model predictions saved as `submission_*.csv`.  
- **Reproducible tuning logs**: Saves `tuning_summary.json` with model, params, and CV score.

---

## ğŸ“‚ Repository structure

```
titanic-ml/
â”œâ”€â”€ data/                  # raw CSVs (not tracked in git)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ features.py        # feature engineering + preprocessors
â”‚   â”œâ”€â”€ train.py           # baseline CV + submission
â”‚   â”œâ”€â”€ tune.py            # compare Logistic, RF, HGB and pick best
â”‚   â”œâ”€â”€ ensemble.py        # soft-vote LR + RF with weight sweep
â”‚   â”œâ”€â”€ hgb_tune.py        # standalone tuner for HGB
â”‚   â”œâ”€â”€ utils.py           # paths + helpers
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ environment.yml        # conda environment
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```
---

## ğŸƒ Usage

### Baseline training
Runs Logistic Regression + Random Forest with CV, picks the better, and writes `submission.csv`:

```bash
python -m src.train
```

### Model tuning (Logit vs RF vs HGB)
Performs hyperparameter search for all three and saves the best:

```bash
python -m src.tune
```

Outputs:
- `submission_<Model>_<CV>.csv` â†’ upload to Kaggle
- `tuning_summary.json` â†’ stores params + CV score

### Ensemble sweep
Trains a soft-vote LR + RF ensemble with weight grid and submits the best:

```bash
python -m src.ensemble
```

### Optional: dedicated HGB tuning
```bash
python -m src.hgb_tune
```

---

## ğŸ“ˆ Results

On cross-validation (5-fold stratified):

- Logistic Regression: ~0.82â€“0.83  
- Random Forest: ~0.83â€“0.84 (tuned)  
- HistGradientBoosting: competitive, often 0.83â€“0.84  
- **Soft-vote Ensemble (LR + RF)**: **~0.8395 CV**
